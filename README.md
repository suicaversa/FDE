# Facebook Data Extractor(FDE)
- FacebookAPIを使って、過去の投稿ログを取得するツール。  
  あらゆる投稿の本文、投稿日、位置情報、写真リストをjson化して取得。
- 日付で取得範囲を指定する。
- 取得後、json形式でダウンロードが行われる。

## 初期セットアップ
### env設定
- プログラムのルートディレクトリに.envというファイルを作成し、以下の項目の設定が必要。または、同じ環境変数を設定してもOK。
  > SESSION_SECRET= : セッション管理要のランダムな文字列
  > FB_APP_ID= : FacebookAPI利用のためのAPP_ID
  > FB_APP_SECRET= : FacebookAPI利用のためのAPP_SECRET
  > AWS_ACCESS_KEY : 取得したデータをS3に保存するためのKEY
  > AWS_ACCESS_SECRET : 取得したデータをS3に保存するためのKEY
  > AWS_S3_BUCKET : 取得したデータを保存する先のS3 Bucket
  > GOOGLE_MAP_APIKEY : GoogleMapのAPIKEY

## 今後対応予定のオプション
- ピンクリックの中身を綺麗にする
- mapから選ばせるのではなく、日付でピンを絞り込む。情報が足りなければそのタイミングで取得する方式。  
  取得済み期間はファイル名で判断。どんどんjoinしていく。
- ピンを打つ個数を制限する。時系列順に、200個が最大。  
  制限されたら、最後のピンで終了してuntilをその日付にする。
- 基本は、mapピンのみ。ダウンロードはコンパネ下部に、RAWDL: 該当期間 or 全部をDLボタンを入れる。
- 追加で検索機能を入れる。  
  messageのKW検索、place_nameのKW検索。
- mapで表示するボックスの中身をもう少し見やすく修正する。
- レスポンシブ対応

---
## 毎回取得するのではなく、範囲指定して取得する仕組みづくり
- データの保存先をDBに変更
  >  amazonのRDS使う。
  >    users
  >      id
  >      facebook_token
  >      facebook_fetched_periods : ,区切り。_で日付join
  >      created_at
  >      last_login
  >    posts
  >      created_at
  >      message
  >      ... など、調理後のデータ
  >      raw : 取得した生json


- 取得の要不要を検証して、APIを叩く。
  - ただし、再取得モード時は、指定した期間は検証無しで取得し、該当期間のpostsを削除して上書き。
  - 検証方法
    入力した期間が全部periodに含まれていれば取得不要。  
    一部でも含まれていなければ全取得して上書き。  
    >  facebook_fetched_periods : 取得済み期間 例: 2017-01-01_2017-07-30(split(",").map{|p| p.split("_")}で区間作成。)
    >  - 基本的に指定された期間分を毎回取得。全部含まれているときのみキャッシュを利用。
    >    B-C取得済みのとき、A-D取ると A-B,C-Dの2つの取得が必要。バッチリクエストで取得か。とはいえ、n個まであり得る。
    >    1件とか含まれている限りは取っても良いけど、100個とかならとらないほうが良い。
    >    とはいえ、1件とかがまばらに含まれているとAPIリクエストがn個まで増える。
    >    n個まで増えると意図せずスパムできてしまう。重複がある分には想定されているので、問題ないはず。
    >    ということで基本的に指定された期間分を毎回取得。全部含まれているときのみキャッシュを利用。

- viewの変更  
  リストに表示するのは、入力期間の投稿の日付。
  見た目的にはiphoneのリスト表示的な感じ。

- 制約
  mapへ指すピンが多すぎるとフリーズする。念のため、n=200個で制限したほうが良い。
  コンパネ下部で選択可能に。RESTで表現。データ量が多すぎてパケ死あり得るので、
  そもそも取得データ数を制限したほうが良さそう。

- 意識しておく
  本文での絞り込み、位置情報での絞り込みなどあり得るのでcontrollerの設計は気をつける。

- ここまでやるなら、railsでも良い気がしてきた、、
